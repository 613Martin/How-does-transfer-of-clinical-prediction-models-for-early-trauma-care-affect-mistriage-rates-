---
title: "Mistriage"
author: "Martin Henriksson"
date: "190517"
output: word_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
## LOADING ENVIROMENT AND TABLES
## Original results and UI tables
results <- readRDS("output/original.results.Rds")
result.tables <- readRDS("result.tables.Rds")
result.tables.data.frame <- readRDS("result.tables.data.frame.Rds")
## Sample characteristics table
# table.one <- 

## PREPARED CODE
## Total patients and NA
total.number.of.patients <- nrow(results$data.sets.before.imputations$multi.centre.vs.single.centre$multi.centre)
total.number.of.na <- results$NA.info.sample$multi.centre.vs.single.centre$multi.centre$total.number.of.na
## Sample NA
na.vector <- unlist(results$NA.info.sample)
highest.percent.missing.number <- max(na.vector[na.vector<100])
highest.percent.missing.name <- names((na.vector[na.vector == highest.percent.missing.number]))
## Variable NA
number.variable.na <- max(results$NA.info.variable$multi.centre.vs.single.centre$multi.centre$number.of.na)
percent.variable.na <- results$NA.info.variable$multi.centre.vs.single.centre$multi.centre$percentage[results$NA.info.variable$multi.centre.vs.single.centre$multi.centre$number.of.na == number.variable.na]
name.variable.na <- row.names( results$NA.info.variable$multi.centre.vs.single.centre$multi.centre[results$NA.info.variable$multi.centre.vs.single.centre$multi.centre$number.of.na == number.variable.na,] )
gcs.na <- (results$NA.info.variable$multi.centre.vs.single.centre$multi.centre[row.names(results$NA.info.variable$multi.centre.vs.single.centre$multi.centre) == "ed_gcs_sum",])
sbp.na <- (results$NA.info.variable$multi.centre.vs.single.centre$multi.centre[row.names(results$NA.info.variable$multi.centre.vs.single.centre$multi.centre) == "ed_sbp_value",])
## Development and validation
high.low.imp <- results$original.stats$Total.imputations[results$original.stats$Sample.name == "high.volume"]
metro.non.imp <- results$original.stats$Total.imputations[results$original.stats$Sample.name == "metropolitan"]
multi.single.imp <- results$original.stats$Total.imputations[results$original.stats$Sample.name == "multi.centre"]
max.imp <- max(results$original.stats$Total.imputations)
best.validation <- results$original.stats[results$original.stats$Validation.mistriage.median == min(results$original.stats$Validation.mistriage.median),]
## Comparison
best.transfer <- results$original.stats[results$original.stats$Transfer.mistriage.median == min(results$original.stats$Transfer.mistriage.median),]
worst.transfer <- results$original.stats[results$original.stats$Transferred.mistriage.minus.buddy.local.mistriage.median == max(results$original.stats$Transferred.mistriage.minus.buddy.local.mistriage.median),]

## Table setup
# Table 1 = Sample characteristics table
#
# Table 2 = result.tables, cropped to only show validation
table.2 <- lapply(result.tables.data.frame, function(x) x[1:3,])
table.2 <- lapply(table.2, function(result) {
           kable(result, format = "markdown")
           })
# Table 3 = Cropped to only show transfer
table.3 <- lapply(result.tables.data.frame, function(x) x[4:6,])
table.3 <- lapply(table.3, function(result) {
           kable(result, format = "markdown")
           })
# Table 4 = Cropped to only show transfer differance
table.4 <- lapply(result.tables.data.frame, function(x) x[7:9,])
table.4 <- lapply(table.4, function(result) {
           kable(result, format = "markdown")
           })
```
# Introduction
Trauma results in millions of deaths annually across the globe, and road traffic injuries are among the top 10 leading causes of death worldwide (1, 2). Each year 9% of the world’s deaths are because of trauma, and predictions indicate that this number is likely to increase (3). 

Trauma care involves many levels of the health care system. In a typical, high resource setting, the initial management of patients is performed on the scene of the trauma by Emergency Medical Services (EMS). In this prehospital phase; patient data, vital signs and scene information is collected and transferred to the receiving hospital. This information is then evaluated with the help of a system to determine the level of trauma and prepare adequate resources (4). The level of trauma dictates if a full or limited trauma team is activated (5). 

Systems to determine the level of trauma can be based on clinical prediction models. Such models are continuously being developed and studied, examining different parameters and different contexts concerning trauma care. These models differ in quality and characteristics, but they generally perform well when predicting survival (6). Many of these models are developed in a single standardized setting such as a large metropolitan area or a major trauma centre but are then supposed to be implemented in different settings, such as non-trauma centres.

What is not fully understood is how this transfer affects the performance of these models. Previous research that studied the transfer of clinical prediction models between settings has shown that model performance in terms of calibration can be adversely affected (7). However, the aforementioned research studied model transfers between substantially different settings and did not assess more clinically relevant performance measures, such as misclassification.

In trauma, misclassification is often referred to as mistriage. Here, triage refers to the classification of severity as minor or major trauma. Mistriage can be subdivided into overtriage; the incorrect classification of a patient with minor trauma as major trauma, or undertriage; the incorrect classification of a patient with major trauma as minor trauma. Both are detrimental in terms of patient care and distribution of resources. 

Thus, the effect of model transfers between contexts within the setting of a single health care system, as well as the effect of such transfers on mistriage have not been studied and represent substantial knowledge gaps. Therefore, the aim of this study is to assess how transfers of clinical prediction models for early trauma care between different contexts within a single health system affect mistriage rates.
  
  
# Materials and methods
## Study design
We conducted a registry-based cohort study. Sweden has a nationally encompassing register for registering trauma called SweTrau. We used SweTrau data to create clinical prediction models, which we then transferred between different contexts to study the effects on mistriage. Please refer to appendix I for a brief explanatory list of the statistical terminology.

## Setting
In Sweden, trauma is the most common cause of death before 44 years of age. It is estimated that up to 10% of all major trauma patients suffer some form of disability. The societal effects of trauma are also substantial; with the loss of work days comparable to those lost from cardiovascular and malignant diseases combined (5).

The trauma care organization in Sweden is usually clearly defined in major metropolitan areas (albeit the specific routines differ), and trauma patients are transported directly to a predesignated hospital with specific trauma competency and capacity. In large, more rural parts of the country, trauma patients are instead transported to the nearest hospital for stabilization. Once stabilized, they may then be transported to hospitals with more advanced trauma care capacity (19). Most hospitals in Sweden use some form of system to categorize the level of trauma and necessary response. These systems are usually based on the patient's vital signs and injury mechanism, as reported by the EMS before patient arrival, or as registered in the emergency department if the patient arrives by other means (16).

We used data from SweTrau between 2011 and 2016, as this study’s inception was in 2016 and data obtained the same year. Today 95,5% (52 of 55) of Swedish hospitals record trauma cases in SweTrau. Currently the registry includes 55 000 cases, and the board encourages its use in both academic research and more local quality improvement initiatives (20). Included hospitals are both university and non-university hospitals, all of which receive trauma patients.

Patient data is recorded upon arrival to the hospital. All hospital personnel can perform patient registration, but it is recommended they received Abbreviated Injury Scale (AIS) training. The SweTrau inclusion criteria are: Traumatic event with subsequent activation of hospital trauma protocol, admitted patients with NISS (New Injury Severity Score) > 15 and patients transferred to the hospital within 7 days of traumatic event with NISS > 15. SweTrau excludes patients if the only traumatic event is chronic subdural hematoma or if hospital trauma protocol is activated without traumatic event (21).

## Participants 
The eligibility criteria are patients registered in SweTrau, and age 15 or above. This age was decided as the study aims to study adult trauma and not paediatric trauma which differs in physiology, triage and initial care (22). We recognize this age cut-off is not completely without controversy. However, in Sweden patients age ≥15 go to the adult emergency rooms and the Swedish guidelines for trauma activation define children as age <15 (16). Also, several guidelines and protocols listed in ATLS use age ≥15 as cut-off (9). Patient age was obtained from the SweTrau register.

## Variables
### Model predictors
Our clinical prediction models included the predictors SBP, RR and GCS on arrival to hospital. The rationale for including these three predictors is that they are part of many established clinical prediction models for early trauma care, such as the Revised Trauma Score (23).

### Model outcome
The outcome that we used to develop the clinical prediction models was all cause mortality within 30 days of the trauma.

### Participant characteristics
To describe the patient cohort we reported age, sex, ASA physical status classification system, Injury Severity Score (ISS) and New ISS (NISS).

### Study outcome
We used ISS > 15 as the gold standard to define trauma severity as major trauma, and hence patients with ISS ≤ 15 were considered minor trauma (24). We defined overtriage as the event when a clinical prediction model classified a patient with ISS ≤ 15 as major trauma, and undertriage as the event when a clinical prediction model classified a patient with ISS > 15 as minor trauma. Clinically, in the event of overtriage, a full trauma team is activated and tasked with the care of a minimally injured patient. The opposite is true with undertriage, where a patient with serious injuries is managed with (potentially) inadequate resources  (10). We defined the overtriage rate as the number of overtriaged patients divided by all patients. We defined the undertriage rate as the number of undertriaged patients divided by all patients. The mistriage rate was defined as the sum of the over- and undertriage rates.

## Data sources and measurements
Model predictors, outcome, participant characteristics and study outcome as outlined above will all be obtained from the SweTrau registry. The method of measurement for the model predictors is not specified (for example, if SBP is measured using an automated cuff or manually) in the registry entries. In Swedish emergency rooms, patient parameters are usually obtained by a registered nurse or assistant nurse and are assumed to be accurate. 
Whether the patient is dead or alive 30 days after trauma is manually entered into the registry locally, by each respective hospital. Foreign citizens discharged within 30 days are registered as survivors. Participant characteristics; sex and age are obtained from the patient file before being registered in SweTrau. ASA, NISS and ISS are calculated by hospital personal based on the patient’s injuries, and registered.

## Bias
Data analysis was conducted in a step-by-step fashion, and according to a prearranged analysis plan. The analysis plan and statistical analysis code was finalised using simulated data instead of the real data. These efforts were taken to avoid confirmation bias when conducting the data analysis. The analysis plan was reviewed by an experienced statistician and programmer prior to implementation to ensure objectivity. Neither outcome nor variable were blinded when conducting data analysis, which made a structured objective approach even more important.

## Study size
All patients matching eligibility criteria are listed above. Four data sets were used to study the transfer of clinical prediction models, each data set representing a different setting. Data set, and sample size considerations are outlined below.

## Quantitative variables
SBP and RR was modelled using restricted cubic splines with four knots whenever possible, placed at equally spaced percentiles and GCS as a continuous linear term. When describing the participant characteristics all quantitative variables were to be presented as continuous. ISS was also presented as dichotomous using ISS > 15 as the cutoff.

## Statistical methods
### Data sets
The complete SweTrau cohort was split into four sets of data. High and low volume centres, metropolitan and non-metropolitan centres, multi and single centre data and individual centres.

### High and low volume centres
Based on number of patients, two samples were derived from this data set. High volume centres were those with in the top quartile of number of patients received. The rest were low volume centres. 

### Metropolitan and non-metropolitan centres
This data set was also split into two samples. The metropolitan sample consisted of greater Stockholm, greater Gothenburg and greater Malmö, as defined by statistics Sweden. The other sample was patients from non-metropolitan areas.

### Multi and single centre data
In this data set multiple samples were created. Each centre with large enough sample size to develop and validate a model were their own sample. The multi-centre sample consisted of the combined data from all centres.

### Indicidual centres
This data set was also be split into multiple samples. Each centre with large enough sample size to develop and validate a model constituted its own sample. This data set was removed in the final version of the study due to a lack of centres with a large enough sample size.

### Development and validation sample
Each data set included at least two samples. The samples were then split into two subsamples using a temporal split based on the date of traumatic event. The earlier subsample was the development sample, and the later subsample the validation sample. The development sample contained 70 events (events being patients who died within 30 days of the trauma) and all non-events (non-events being patient survival 30 days past the trauma) during the same time. The rationale for including 70 events is that we needed at least 10 events per free parameter in the logistic regression to obtain stable coefficient estimates (25). The validation sample instead contained 100 events and at least 100 non-events, which was suggested as the minimum number by Vergouwe in 2005 for external validation samples (26). See figure 1 for example using the high- and low volume centre data set, with high volume centres being those in the top quartile of number of patients registered.

![**Figure 1** High- and low volume centre data set. Initial split based on number of patients. Temporal split made using date of traumatic event.](fig1.jpg)

The minimum sample size of development and validation samples was 140 and 200 respectively. The total number of events and non-events per data set was therefore at least 680. We performed analyses only on data sets for which all samples included at least the minimum number of patients.

### Sequence of analysis
The programming language R was used for all analyses (27), and all progress was uploaded to a GitHub repository for inspection (28). We performed the analyses in the sequence of model development, model validation and finally model comparison. These steps were repeated in each data set. Below we used the transfer of a model from a high-volume sample to a low volume sample as an example to describe the complete procedure. 

### Model development
In the model development step a clinical prediction model was developed in the high-volume centre development sample. The model was developed using logistic regression as implemented in the R function glm. The dependent variable was all cause mortality within 30 days of trauma and independent variables SBP, RR, and GCS modelled as previously described. To avoid overfitting the model we used a bootstrap procedure to estimate a linear shrinkage factor that we then applied to the model coefficients (29). The shrunk model was then used to estimate the probability of all cause 30-day mortality in the development sample. We then performed a gridsearch across estimated probabilities in the development sample to identify the cut-off that optimised overtriage keeping undertriage at less than 5% (11). This cut-off was then used to classify patients as major or minor trauma. 

### Model validation
In the model validation step, the model performance was assessed in the high-volume centre validation sample and in the low volume centre validation data. First the model was used to estimate the probability of all cause 30-day mortality in each sample. Then the probability cutoff identified in the development sample was applied to the validation samples, patients were classified as major or minor trauma, and model performance was estimated.

### Model comparison
Finally, in the model comparison step, the difference in model performance between the high and low volume centre validation samples was calculated. We used an empirical bootstrap to estimate 95% confidence intervals (CI) around performance and differences in performance estimates. Both bootstrap procedures used 1000 bootstrap samples drawn with replacement of the same size as the original samples. The three steps of model development, model validation, and model comparison were repeated in all four sets of data.

### Performance measures
Model performance was assessed in terms of over-, under-, and mistriage rates as defined above.

### Missing data
We used multiple imputation using chained equations, as implemented in the R package mice, to handle missing data (30). The number of imputations created for each data set was equal to the highest percentage of missing data in that data set. Quantitative variables were imputed using predictive mean matching and qualitative variables were imputed using logistic regression. SBP and RR was transformed as restricted cubic splines before imputation and imputed as just another variable. All analyses outlined above were then conducted separately in each imputed dataset. We present the combined results as the median point estimate across imputations along with an empirical bootstrap of the 25th and 75th percentiles across imputations, i.e. the lower bound of the presented interval is the lower bound of a 95% CI of the 25th percentile and the upper bound is the upper bound of a 95% CI of the 75th percentile. This combined CI was referred to as an Uncertainty Interval (UI) and was used to express the added uncertainty associated with the imputation procedure to handle missing data, as such it is more conservative than a standard 95% CI.

## Ethical considerations
This study was conducted in accordance with the four major principles of medical ethics and The Declaration of Helsinki (31, 32).

### Respect for autonomy
The respect for autonomy was upheld as Swedish Privacy Law requires the informed consent of all participants. Patients included in SweTrau receive letters detailing that data obtained may be used for scientific purposes. They are also informed that participation is voluntary and that they may withdraw at any time. 

### The Principle of Beneficence
Throughout the entire study we attempted to act in the best interest of the patients. In the long run we hope this research will improve the care of trauma patients, and therefore prove beneficial to those affected. We also believe that the patients who consented to research want to contribute to this improvement of care, and as thus by performing this study we hope to honour their wishes.

### The Principle of Nonmaleficence
All attempts were made not to harm any patients included in this study, either intentionally or unintentionally.  Data leakage and patient identification constitutes the primary risk. All data obtain was depersonalized and handled with care to minimize risk of unauthorised access and subsequent patient identification. By implementing these actions, we determined that the risk to the patient population is minimal.

### The Principle of Justice
As this study contained no intervention, the principle of justice does not truly apply. However, all cases included from the registry were treated as equal. It is also our wish that any scientific gains this study may contribute will be implemented in a fair and equal fashion.

### Ethical permit
This study is approved by the regional ethics review board in Stockholm, Sweden. Ethical review numbers are 2015/426-31 and 2016/461-32.
  
  
# Results
We analysed data from `r total.number.of.patients ` trauma patients to investigate the effects of transfer on clinical prediction models (Table 1). The total number of missing observations across all variables was `r total.number.of.na ` in the entire study cohort. The sample with the highest percentage of missing observations was the `r highest.percent.missing.name ` sample with `r highest.percent.missing.number `% incomplete observations. The variable with the highest number of missing values was `r name.variable.na `, with `r number.variable.na ` missing values, which constituted `r round(percent.variable.na) `% of the total values for this variable. The percentages of missing values for the other model predictors, GCS and SBP was `r round(gcs.na$percentage)`% and `r round(sbp.na$percentage)`% respectively.

```{r, echo = FALSE, results = "asis"} 
## Table 1 = Sample characteristics table
#
``` 

## Development and validation
During model development, the number of imputations used for each data set was `r high.low.imp`, `r metro.non.imp` and `r multi.single.imp` for the high and low volume data set, the metropolitan and non-metropolitan data set and the multi and single centre data set respectively. This number was equal to the maximum percentage of missing observations for each sample in the respective data sets. Restricted cubic splines with four knots placed at equally spaced percentiles were implemented when modelling systolic blood pressure and respiratory rate. 1000 bootstrap samples drawn with replacement was used to estimate a linear shrinkage factor that was applied to the developed models to avoid model overfitting.
  
Table 2 shows model validation performance. Model validation performance refers to the model performance when applied in the validation subsample from the sample in which it was developed. The sample with the best validation model performance was the `r best.validation$Sample.name` sample with a median mistriage rate of `r best.validation$Validation.mistriage.median`. Performance in terms of under and overtriage for the same model was `r best.validation$Validation.undertriage.median`, and `r best.validation$Validation.overtriage.median`. Model validation performance varied across all samples with a median mistriage rate range of `r min(results$original.stats$Validation.mistriage.median)` - `r max(results$original.stats$Validation.mistriage.median)`. Uncertainty interval(UI) for validation mistriage, undertriage and overtriage ranged from ... to ... across all samples.

```{r, echo = FALSE, results = "asis"} 
## Table 2 = Cropped to only show validation
table.2
```

## Comparison
Model performance after transfer was determined for each model being transferred to the other sample in the data set in all data sets (Table 3). When transferred, the model with the best performance i.e. lowest mistriage rate was the `r best.transfer$Sample.name` model with a median mistriage of `r best.transfer$Transfer.mistriage.median`. Concerning the UI for transfer mistriage, undertriage and overtriage, this too ranged from 0 to 0.830 across all samples.
  
```{r, echo = FALSE, results = "asis"} 
## Table 3 = Cropped to only show transfer
table.3
```  
   
The main purpose of this study was to examine the transferability of clinical prediction models for trauma. Table 4 shows the transferred model performance when compared to the validation performance in the same sample, transferred model performance varied between samples and data sets. 

The lowest model performance when compared to the sample validation performance was found in the `r worst.transfer$Sample.name` sample, with a median mistriage difference of `r worst.transfer$Transferred.mistriage.minus.buddy.local.mistriage.median`, meaning this model performed worse when transferred to the other sample in the same data set, when compared with the model developed and validated in this sample. In clinical terms, this model transfer means that among 100 trauma patients, `r abs(worst.transfer$Transferred.mistriage.minus.buddy.local.mistriage.median) * 100` more patients would be wrongly classified as major or minor trauma. However, when uncertainty intervals (UI) were obtained no observed differences between transferred model performances and validation model performances in any sample were found to be significant.

```{r, echo = FALSE, results = "asis"} 
## Table 4 = Cropped to only show transfer differance
table.4
``` 
  
  
# Discussion (Needs update with code snippets) 
This study aimed to assess how transfers of clinical prediction models for early trauma care between different contexts within a single health system affect mistriage rates. The most notable effects on model performance following model transfer compared to the original sample model was seen when the metropolitan model was transferred to the non-metropolitan sample. The performance of the metropolitan model transferred to the non-metropolitan sample was a mistriage rate of ..., and the validation mistriage rate of the non-metropolitan model was .... This indicates that the mistriage increased by ... when using the metropolitan model in a non-metropolitan setting. Mainly contributing to this increase in mistriage was the marked increase in overtriage when performing this model transfer. The UI of this difference however ranged from ... to ..., indicating that our findings are compatible with a ... decrease to ... increase in mistriage. This means that with the negative UI (...), the effect of transfer would be an improvement in model performance. The upper limit of the UI (...) would mean a marked decrease in model performance, especially compared to the point estimate of ....

The transfer of clinical prediction models in trauma care has not previously been extensively studied. In 2016, Gerdin et al. also found model transfer to adversely affect model performance (18). They found the transferred model to perform poorly in terms of calibration, and that this could be improved by updating the model. In our current study we did not examine model performance in terms of calibration, neither did we examine the effects of updating the model. What the two studies have in common is an observed decline in model performance, when transferring the models between certain settings. Therefore, we believe model transfer can potentially lead to a decline in model performance compared to the setting in which it was originally developed.  Model transfer should be performed with caution, and the effects examined before implementing the transferred model in a clinical setting.

External validation of clinical prediction models, meaning the evaluation of a clinical prediction model in a setting in which it was not originally developed has however been studied more extensively. The concepts of external validation are applicable and comparable to our current study, with the exception being that out models were technically externally validated using a validation subsample before being transferred to an entirely different sample. Studies using simulated clinical prediction models based on different predictors often show a decline in model performance when being externally validated (33, 34), both underlining the necessity of testing models in other populations before clinical use. A study from 2018 examining the external validity of prediction models for coronary artery disease (CAD) (35), showing models significantly underestimating the probability of CAD. Our study did not show the same dramatic decrease in model performance after transfer but combined with the results of other studies of external validation it further warrants caution when transferring models between different settings.

## Strengths and limitations
This study examined model transfer in a limited setting (Sweden, as a single health care setting), which has advantages and disadvantages. The study design realistically reflects potential transfers: clinical prediction models for trauma are usually developed in large metropolitan centres and then transferred as clinical recommendations to minor non-metropolitan centres in which traumatic injuries are not as common. 

In terms of disadvantages these results are restricted to a single health care system in Sweden, and the generalizability to other health care systems might be limited. Also, the small number of patients (27043) weakens the applicability of the results on a more general setting. We originally intended to study all single centres with a valid number of events, but when performing the analysis only one centre provided a sufficient number of events for study. Leading to the loss of the fourth data set: Individual centres, and the comparison between these. We recognize that the results this data set might have provided could reflect realistic situations as major trauma centres regularly exchange data to improve patient care.

In Sweden major trauma is relatively uncommon, especially in non-metropolitan and minor centres, and therefore it is reasonable to assume this leads to inconsistencies when performing SweTrau patient registration. Such as using NISS instead of ISS, registering SBP by category and not by absolute value, not following up on patient survival, or other local differences. This might lead to exaggerated performance differences between the different settings, as the transferred models are based on registry data.

We developed models using logistic regression based on registry data, instead of using pre-developed models such as the Revised Trauma Score, eliminating the risk of potentially misrepresenting already established models. The models used in this study used GCS, RR and SBP as predictors for 30-day mortality. Potentially, the use of additional predictors such as age, mechanism of injury, or newer predictors as chock index might increase model performance. Furthermore, we used 30-day mortality as an outcome. We recognize that late mortality, time in hospital, functional impairment, and morbidity are also important outcome factors in the context of trauma care.

Statistical analysis and comparisons were performed using R. We aimed to follow a predetermined analysis plan in a step-by-step fashion with to aim of avoiding confirmation bias. However, programming challenges and late-time code inclusions required a flexible approach to this analysis plan, with revisions of previous steps. We recognize that this is not optimal but aimed to maintain objectivity by not deviating in any major way from the analysis plan. Using GitHub, all code was made public for inspection and to ensure reproducibility (28).

## Clinical applications
Clinical prediction models are constantly being developed in different contexts, and often transferred to settings in which they were not originally developed. The results of this study show that mistriage can potentially increase following model transfer, in this case more prominently when transferring from a metropolitan setting to a non-metropolitan setting. This supports the view that model transfers should be done with caution, as performance might decline.

Recognizing these risks and updating the models accordingly will lead to an increased accuracy during the triage of trauma patients. This could potentially save lives by minimizing undertriage, and likely save resources by minimizing overtriage. Potentially, because of registries such as SweTrau, analysis of model transfer could be performed continuously to optimize models currently in use and advise which model transfers might be detrimental (or potentially beneficial).

## Future studies
To increase the generalisability, studies of this type could be performed in different settings e.g. assessing the transferability between different countries, such as Sweden and the United Kingdom. Also, increasing the number of patients would also increase the power of the study results, one potential way of doing this would be to replicate this study using the very latest data in the SweTrau registry, as many hospitals have joined recently which in turn has led to an increase in the number of patients registered. 

Model transfer could potentially be studied using different methods. Quite often, as mentioned, clinical models are transferred from a major metropolitan centre to a smaller rural centre. Staff opinions considering how applicable this new model is could be obtained using an interview or questionnaire approach Clinical trials using different models could also be performed, however, appropriate ethical considerations are paramount before performing this type of study.

In terms of equity, patient sex and age were obtained to characterize the patient cohort: 66 % male, and a median age of 41 (mean 44). No actions were undertaken in response to this division. Further studies might aim to examine if model performance differs using sex or age as a predictor.

## Conclusion (Needs update with code snippets) 
A clinical prediction model developed using logistic regression and GCS, RR and SBP as predictors can be used to predict 30-day mortality in different settings. Model transfer in the metropolitan and non-metropolitan data set lead to ... mistriage rate (95% UI ...). This was mainly due to .... In all samples, 95% UI for model transfer comparison included 0. Poor model transfer can potentially lead to increased patient mortality and a misappropriation of resources. We recognize the limitations of this study, but believe further studies are warranted due to the potentially severe patient consequences. 

  
# References
